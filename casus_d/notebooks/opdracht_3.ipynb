{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Opdracht 3 Soort van YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO\n",
    "je hebt een grid en bepaald wat is de kans dat dit celletje de centrale cel is van bijvoorbeedl een plaatsje van een hond. Het model doet een voorspelling. YOLO is een pytorch ding. we gebruiken het model dat al gebruikt is om images te detecteren. Kijken waar er bounding boxes zijn. missende data, de totale oppervlak van het plaatjem hoeveel wordt opgevuld door tegels?\n",
    "Oppervlak keer 250? en dan krijg je de opvulling, check of dit correct is. per plaatje breedte en hoogte bepalen. Per afbeelding een bestand maken voor de labels directory. Coords-idc.txt is een plaatje en de bounding box van tumoren. linksboven naar rechtsonder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laad libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data omzetten naar YOLO-formaat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functie om annotaties om te zetten naar YOLO-formaat\n",
    "def convert_to_yolo_format(coords_file, images_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Converteert annotaties van een CSV-bestand naar YOLO-formaat.\n",
    "\n",
    "    Parameters:\n",
    "    - coords_file (str): Pad naar het CSV-bestand met annotaties.\n",
    "    - images_folder (str): Map met afbeeldingsbestanden.\n",
    "    - output_folder (str): Map om de YOLO-annotaties op te slaan.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Maak output map aan als die nog niet bestaat\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Laad annotaties\n",
    "    coords = pd.read_csv(coords_file, header=None, names=[\"image_id\", \"xmin\", \"ymin\", \"xmax\", \"ymax\"])\n",
    "\n",
    "    for image_id in coords[\"image_id\"].unique():\n",
    "        # Selecteer alle annotaties voor een afbeelding\n",
    "        image_coords = coords[coords[\"image_id\"] == image_id]\n",
    "        \n",
    "        # Bereken de afmetingen van de afbeelding\n",
    "        image_path = os.path.join(images_folder, f\"{image_id}.jpeg\")\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Afbeelding {image_path} niet gevonden.\")\n",
    "            continue\n",
    "        \n",
    "        from PIL import Image\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "\n",
    "        # Genereer YOLO-annotaties\n",
    "        yolo_annotations = []\n",
    "        for _, row in image_coords.iterrows():\n",
    "            x_center = ((row[\"xmin\"] + row[\"xmax\"]) / 2) / width\n",
    "            y_center = ((row[\"ymin\"] + row[\"ymax\"]) / 2) / height\n",
    "            bbox_width = (row[\"xmax\"] - row[\"xmin\"]) / width\n",
    "            bbox_height = (row[\"ymax\"] - row[\"ymin\"]) / height\n",
    "            yolo_annotations.append(f\"1 {x_center} {y_center} {bbox_width} {bbox_height}\")\n",
    "\n",
    "        # Schrijf annotaties naar bestand\n",
    "        annotation_path = os.path.join(output_folder, f\"{image_id}.txt\")\n",
    "        with open(annotation_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(yolo_annotations))\n",
    "\n",
    "# Bestandspaden\n",
    "coords_file = \"../data/coords-idc.txt\"\n",
    "images_folder = \"../data/complete_images\"\n",
    "output_folder = \"../data/yolo_labels\"\n",
    "convert_to_yolo_format(coords_file, images_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory-structuur creëren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_structure(images_folder, labels_folder, output_folder, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Creëert een gestructureerde dataset met een training- en validatieset.\n",
    "\n",
    "    Parameters:\n",
    "    - images_folder (str): Map met afbeeldingsbestanden.\n",
    "    - labels_folder (str): Map met YOLO-annotaties.\n",
    "    - output_folder (str): Doelmap voor gestructureerde dataset.\n",
    "    - train_ratio (float): Ratio van training-data tot validatie-data.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Maak mapstructuur\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        os.makedirs(os.path.join(output_folder, \"images\", split), exist_ok=True)\n",
    "        os.makedirs(os.path.join(output_folder, \"labels\", split), exist_ok=True)\n",
    "\n",
    "    # Verdeel data in training- en validatiesets\n",
    "    image_files = [f for f in os.listdir(images_folder) if f.endswith(\".jpeg\")]\n",
    "    random.shuffle(image_files)\n",
    "    train_split = int(len(image_files) * train_ratio)\n",
    "\n",
    "    splits = {\n",
    "        \"train\": image_files[:train_split],\n",
    "        \"val\": image_files[train_split:]\n",
    "    }\n",
    "\n",
    "    for split, files in splits.items():\n",
    "        for image_file in files:\n",
    "            # Verplaats afbeelding\n",
    "            src_image = os.path.join(images_folder, image_file)\n",
    "            dest_image = os.path.join(output_folder, \"images\", split, image_file)\n",
    "            shutil.copy(src_image, dest_image)\n",
    "\n",
    "            # Verplaats corresponderend label\n",
    "            label_file = image_file.replace(\".jpeg\", \".txt\")\n",
    "            src_label = os.path.join(labels_folder, label_file)\n",
    "            dest_label = os.path.join(output_folder, \"labels\", split, label_file)\n",
    "            if os.path.exists(src_label):\n",
    "                shutil.copy(src_label, dest_label)\n",
    "\n",
    "images_folder = \"../data/complete_images\"\n",
    "labels_folder = \"../data/yolo_labels\"\n",
    "output_folder = \"../data/dataset\"\n",
    "create_dataset_structure(images_folder, labels_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO-configuratiebestand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maak een configuratie-bestand dataset.yaml met daarin de volgende gegevens\n",
    "\n",
    "train: /path/to/dataset/images/train\n",
    "\n",
    "val: /path/to/dataset/images/val\n",
    "\n",
    "nc: 1  # aantal klassen\n",
    "\n",
    "names: ['tumor']  # lijst van klasse-namen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trainen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:00<00:00, 13.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.51  Python-3.12.7 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=dataset.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train25, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=True, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train25\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train25', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\isabe\\Documents\\Hanze\\jaar_3_new\\kw2\\modelleren_van_kanker\\casus_d\\data\\dataset\\labels\\train... 277 images, 0 backgrounds, 1 corrupt: 100%|██████████| 277/277 [00:00<00:00, 727.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\isabe\\Documents\\Hanze\\jaar_3_new\\kw2\\modelleren_van_kanker\\casus_d\\data\\dataset\\images\\train\\12906.jpeg: ignoring corrupt image/label: negative label values [  -0.014904    -0.35914   -0.036478    -0.22465    -0.38828]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\isabe\\Documents\\Hanze\\jaar_3_new\\kw2\\modelleren_van_kanker\\casus_d\\data\\dataset\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\isabe\\Documents\\Hanze\\jaar_3_new\\kw2\\modelleren_van_kanker\\casus_d\\data\\dataset\\labels\\val... 141 images, 1 backgrounds, 0 corrupt: 100%|██████████| 142/142 [00:00<00:00, 358.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\isabe\\Documents\\Hanze\\jaar_3_new\\kw2\\modelleren_van_kanker\\casus_d\\data\\dataset\\labels\\val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train25\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train25\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      4.34G      2.733      4.043      2.572         10        640: 100%|██████████| 18/18 [00:06<00:00,  2.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\nMeta: registered at /dev/null:184 [kernel]\nQuantizedCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\nBackendSelect: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:96 [backend fallback]\nAutogradOther: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradCPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradCUDA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:75 [backend fallback]\nAutogradXLA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:79 [backend fallback]\nAutogradMPS: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:87 [backend fallback]\nAutogradXPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:71 [backend fallback]\nAutogradHPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:100 [backend fallback]\nAutogradLazy: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:83 [backend fallback]\nAutogradMeta: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:91 [backend fallback]\nTracer: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\autograd\\TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:34 [kernel]\nAutocastXPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:41 [kernel]\nAutocastMPS: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:27 [kernel]\nFuncTorchBatched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:157 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isabe\\anaconda3\\envs\\modelleren_van_kanker\\Lib\\site-packages\\ultralytics\\engine\\model.py:806\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 806\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32mc:\\Users\\isabe\\anaconda3\\envs\\modelleren_van_kanker\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isabe\\anaconda3\\envs\\modelleren_van_kanker\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:432\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mval \u001b[38;5;129;01mor\u001b[39;00m final_epoch \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper\u001b[38;5;241m.\u001b[39mpossible_stop \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop:\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_metrics(metrics\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_loss_items(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr})\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness) \u001b[38;5;129;01mor\u001b[39;00m final_epoch\n",
      "File \u001b[1;32mc:\\Users\\isabe\\anaconda3\\envs\\modelleren_van_kanker\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:605\u001b[0m, in \u001b[0;36mBaseTrainer.validate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    600\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;124;03m    Runs validation on test set using self.validator.\u001b[39;00m\n\u001b[0;32m    602\u001b[0m \n\u001b[0;32m    603\u001b[0m \u001b[38;5;124;03m    The returned dict is expected to contain \"fitness\" key.\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# use loss as fitness measure if not found\u001b[39;00m\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;241m<\u001b[39m fitness:\n",
      "File \u001b[1;32mc:\\Users\\isabe\\anaconda3\\envs\\modelleren_van_kanker\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isabe\\anaconda3\\envs\\modelleren_van_kanker\\Lib\\site-packages\\ultralytics\\engine\\validator.py:189\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[1;34m(self, trainer, model)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# Postprocess\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dt[\u001b[38;5;241m3\u001b[39m]:\n\u001b[1;32m--> 189\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_metrics(preds, batch)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mplots \u001b[38;5;129;01mand\u001b[39;00m batch_i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\isabe\\anaconda3\\envs\\modelleren_van_kanker\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:94\u001b[0m, in \u001b[0;36mDetectionValidator.postprocess\u001b[1;34m(self, preds)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpostprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds):\n\u001b[0;32m     93\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply Non-maximum suppression to prediction outputs.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnon_max_suppression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miou\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43magnostic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magnostic_nms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_det\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_det\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isabe\\anaconda3\\envs\\modelleren_van_kanker\\Lib\\site-packages\\ultralytics\\utils\\ops.py:291\u001b[0m, in \u001b[0;36mnon_max_suppression\u001b[1;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, in_place, rotated)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m x[:, :\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m c  \u001b[38;5;66;03m# boxes (offset by class)\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_thres\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# NMS\u001b[39;00m\n\u001b[0;32m    292\u001b[0m i \u001b[38;5;241m=\u001b[39m i[:max_det]  \u001b[38;5;66;03m# limit detections\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;66;03m# # Experimental\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# merge = False  # use merge-NMS\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;66;03m# if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m#     if redundant:\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m#         i = i[iou.sum(1) > 1]  # require redundancy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\isabe\\anaconda3\\envs\\modelleren_van_kanker\\Lib\\site-packages\\torchvision\\ops\\boxes.py:41\u001b[0m, in \u001b[0;36mnms\u001b[1;34m(boxes, scores, iou_threshold)\u001b[0m\n\u001b[0;32m     39\u001b[0m     _log_api_usage_once(nms)\n\u001b[0;32m     40\u001b[0m _assert_has_ops()\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isabe\\anaconda3\\envs\\modelleren_van_kanker\\Lib\\site-packages\\torch\\_ops.py:1116\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[1;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Could not run 'torchvision::nms' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'torchvision::nms' is only available for these backends: [CPU, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\cpu\\nms_kernel.cpp:112 [kernel]\nMeta: registered at /dev/null:184 [kernel]\nQuantizedCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\quantized\\cpu\\qnms_kernel.cpp:124 [kernel]\nBackendSelect: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:96 [backend fallback]\nAutogradOther: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradCPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradCUDA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:75 [backend fallback]\nAutogradXLA: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:79 [backend fallback]\nAutogradMPS: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:87 [backend fallback]\nAutogradXPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:71 [backend fallback]\nAutogradHPU: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:100 [backend fallback]\nAutogradLazy: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:83 [backend fallback]\nAutogradMeta: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:91 [backend fallback]\nTracer: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\autograd\\TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:34 [kernel]\nAutocastXPU: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:41 [kernel]\nAutocastMPS: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: registered at C:\\actions-runner\\_work\\vision\\vision\\pytorch\\vision\\torchvision\\csrc\\ops\\autocast\\nms_kernel.cpp:27 [kernel]\nFuncTorchBatched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:157 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "model.train(data=\"dataset.yaml\", epochs=10, single_cls=True, amp=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voorspellingen doen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model_path, test_images_folder, output_folder):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelleren_van_kanker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
