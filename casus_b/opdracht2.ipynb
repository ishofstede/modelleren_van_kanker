{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opdracht 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import gensim \n",
    "\n",
    "# preprocess de zinnen\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make the matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = np.array('altijd november altijd regen altijd dit lege hart altijd'.split())\n",
    "enc = OneHotEncoder()\n",
    "data = enc.fit_transform(line.reshape(-1, 1))\n",
    "\n",
    "corpus = {'altijd':1, 'dit':2, 'hart':3, 'lege':4, 'november':5, 'regen':6}\n",
    "data = [corpus[k] for k in \n",
    "    'altijd november altijd regen altijd dit lege hart altijd'.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"BioWordVec_PubMed_MIMICIII_d200.vec.bin\"\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "#kijken of het model goed is geladen\n",
    "len(model.key_to_index) #16545452\n",
    "\n",
    "#het model positioneert de woorden in een 200-dimensionale vectorruimte\n",
    "s = model['man']\n",
    "type(s) #ndarray\n",
    "s.shape #(200,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosinusgelijkheid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9746318461970762\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    # # define two lists or array\n",
    "\n",
    "    # A = np.array([2,1,2,3,2,9])\n",
    "    # B = np.array([3,4,2,4,5,5])\n",
    "    # bereken dot product \n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "\n",
    "    # bereken de norm van elke vector\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    # bereken cosinusgelijkheid\n",
    "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "\n",
    "vector1 = np.array([1, 2, 3])\n",
    "vector2 = np.array([4, 5, 6])\n",
    "\n",
    "resultaat = cosine_similarity(vector1, vector2)\n",
    "print(f\"Cosine Similarity: {resultaat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess de zinnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\isabe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwoordenlijst (eenmalig)\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hallo wereld voorbeeldzin diakritische tekens naive resume\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    # Zet om naar kleine letters\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # Verwijder de/het/een tekens\n",
    "    sentence = unidecode(sentence)\n",
    "    \n",
    "    # Verwijder interpunctie en speciale tekens, behoud alleen letters en spaties\n",
    "    sentence = re.sub(r'[^a-z\\s]', '', sentence)\n",
    "    \n",
    "    # Verwijder stopwoorden\n",
    "    stop_words = set(stopwords.words('dutch'))  # Voor Nederlands, gebruik 'english' voor Engels\n",
    "    words = sentence.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Zet de woorden terug naar een zin\n",
    "    processed_sentence = ' '.join(filtered_words)\n",
    "    \n",
    "    return processed_sentence\n",
    "\n",
    "# Voorbeeldgebruik\n",
    "zin = \"Hallo, wereld! Dit is een voorbeeldzin met diakritische tekens: naïve en résumé.\"\n",
    "print(preprocess_sentence(zin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_vector(sentence, model):\n",
    "    # Preprocess de zin\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    # Split de zin in woorden\n",
    "    words = sentence.split()\n",
    "    \n",
    "    # Haal de vectoren op voor de woorden\n",
    "    word_vectors = []\n",
    "    for word in words:\n",
    "        if word in model:\n",
    "            word_vectors.append(model[word])\n",
    "    \n",
    "    # Bereken het gemiddelde van de woordembeddings (indien er woorden zijn)\n",
    "    if word_vectors:\n",
    "        sentence_vector = np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        # Als er geen bekende woorden zijn in het model, retourneer een lege vector\n",
    "        sentence_vector = np.zeros(model.vector_size)\n",
    "    \n",
    "    return sentence_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity tussen zin 1 en zin 2: 0.9913076162338257\n",
      "Cosine Similarity tussen zin 1 en zin 3: 0.9479348063468933\n",
      "Cosine Similarity tussen zin 2 en zin 3: 0.9444634318351746\n"
     ]
    }
   ],
   "source": [
    "# Voorbeeldzinnen\n",
    "zin1 = \"Breast cancers with HER2 amplification have a higher risk of CNS metastasis and poorer prognosis.\"\n",
    "zin2 = \"Breast cancers with HER2 amplification are more aggressive, have a higher risk of CNS metastasis, and poorer prognosis.\"\n",
    "zin3 = \"Furthermore, increased CREB expression in breast tumors is associated with poor prognosis, shorter survival and higher risk of metastasis.\"\n",
    "\n",
    "# Zet zinnen om naar vectoren\n",
    "vec1 = sentence_to_vector(zin1, model)\n",
    "vec2 = sentence_to_vector(zin2, model)\n",
    "vec3 = sentence_to_vector(zin3, model)\n",
    "\n",
    "# Bereken de cosine similarity tussen de zinnen\n",
    "sim12 = cosine_similarity(vec1, vec2)\n",
    "sim13 = cosine_similarity(vec1, vec3)\n",
    "sim23 = cosine_similarity(vec2, vec3)\n",
    "\n",
    "print(f\"Cosine Similarity tussen zin 1 en zin 2: {sim12}\")\n",
    "print(f\"Cosine Similarity tussen zin 1 en zin 3: {sim13}\")\n",
    "print(f\"Cosine Similarity tussen zin 2 en zin 3: {sim23}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelleren_van_kanker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
